---
title: "Tarea 5"
output: html_document
---


1. En la Tarea 4, construye curvas ROC para cada uno de los 
tres modelos (una sola variable, todas las variables, y todas
las variables m??s variables de ruido). ??Cu??l tiene mejor 
desempe??o? Calcula el AUC para cada una de las tres curvas.

### Carga y Preparaci??n de Datos
```{r}
# Carga de datos y funciones
setwd("/Users/deliadelaguila/Documents/GitHub/aprendizaje-maquina-mcd")
source("tarea_4_codigo.R")
library(tidyverse)
datos_titanic <- read_csv("./tarea_4_datos/train.csv")

# Remover duplicados
datos_titanic <- datos_titanic %>% select(Survived, Pclass, Age, Sex, Embarked) %>%
    filter(!is.na(Age), !is.na(Embarked))
datos <- datos_titanic %>% 
         mutate(female = as.numeric(Sex == "female"),
                southampton = as.numeric(Embarked == "S"),
                cherbourg = as.numeric(Embarked == "C")) %>%
        select(-Embarked, -Sex)

#Normalizar
datos$age_n <- datos$Age / 60
datos$pclass_n <-(datos$Pclass - 1) / 3
datos_trans <- datos %>% select(Survived, pclass_n, age_n, female, southampton, cherbourg)

# Separaci??n de datos: Entrenamiento y Prueba
set.seed(1234)
datos_trans <- datos_trans %>% 
    mutate(u = runif(nrow(datos_trans))) 
entrena <- datos_trans %>% filter(u <= 0.7) %>% select(-u)
prueba <- datos_trans %>% filter(u > 0.7) %>% select(-u)
x_ent <- as.matrix(entrena %>% select(-Survived))
x_pr <- as.matrix(prueba %>% select(-Survived))
y_ent <- entrena$Survived
y_pr <- prueba$Survived

# Ejercicio A: Tomar variable Indicador Abordo en Cherbourg
x_ent_1 <- x_ent[ , "cherbourg", drop = FALSE]
```

### Curva ROC 1

```{r}
library(tabplot)
mod_1 <- glm(y_ent ~ x_ent_1, family = 'binomial')
mod_1
```

```{r}
probs_prueba_1 <- predict(mod_1, type = "response") 

library(ROCR)
library(ggplot2)
pred_rocr_1 <- prediction(probs_prueba_1, y_ent) 
perf_1 <- performance(pred_rocr_1, measure = "sens", x.measure = "fpr") 
perf_1
```

```{r}
graf_roc_1 <- data.frame(tfp = perf_1@x.values[[1]], sens = perf_1@y.values[[1]], 
                       d = perf_1@alpha.values[[1]])

ggplot(graf_roc_1, aes(x = tfp, y = sens, colour=d)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 
```

```{r}
auc_1 <- performance(pred_rocr_1, measure = 'auc')@y.values
auc_1[[1]]
```

### Curva ROC 2

```{r}
x_ent_2 <- x_ent
mod_2 <- glm(y_ent ~ x_ent_2, family = 'binomial')
probs_prueba_2 <- predict(mod_2, type = "response") 

pred_rocr_2 <- prediction(probs_prueba_2, y_ent) 
perf_2 <- performance(pred_rocr_2, measure = "sens", x.measure = "fpr") 
graf_roc_2 <- data.frame(tfp = perf_2@x.values[[1]], sens = perf_2@y.values[[1]], 
                       d = perf_2@alpha.values[[1]])

ggplot(graf_roc_2, aes(x = tfp, y = sens, colour=d)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 
```

```{r}
auc_2 <- performance(pred_rocr_2, measure = 'auc')@y.values
auc_2[[1]]
```

### Curva ROC 3

```{r}
set.seed(201)
p_ruido <- 50 # agregamos 50 variables sin informaci??n
n_ent <- nrow(x_ent)
n_pr <- nrow(x_pr)
mat_ent <- matrix(runif(n_ent * p_ruido), n_ent, p_ruido)
mat_pr <- matrix(runif(n_pr * p_ruido), n_pr, p_ruido)

x_ent_3 <- cbind(x_ent, mat_ent)

mod_3 <- glm(y_ent ~ x_ent_3, family = 'binomial')
probs_prueba_3 <- predict(mod_3, type = "response") 

pred_rocr_3 <- prediction(probs_prueba_3, y_ent) 
perf_3 <- performance(pred_rocr_3, measure = "sens", x.measure = "fpr") 
graf_roc_3 <- data.frame(tfp = perf_3@x.values[[1]], sens = perf_3@y.values[[1]], 
                       d = perf_3@alpha.values[[1]])

ggplot(graf_roc_3, aes(x = tfp, y = sens, colour=d)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 
```

```{r}
auc_3 <- performance(pred_rocr_3, measure = 'auc')@y.values
auc_3[[1]]
```

```{r}
graf_roc_1$modelo <- 'Una variable'
graf_roc_2$modelo <- 'Todas las variables'
graf_roc_3$modelo <- 'Variables aleatorias'
graf_roc <- bind_rows(graf_roc_1, graf_roc_2, graf_roc_3)

ggplot(graf_roc, aes(x = tfp, y = sens, colour = modelo)) + geom_point() +
  xlab('1-especificidad') + ylab('Sensibilidad') 
```


```{r}
auc <- c(auc_1[[1]],auc_2[[1]],auc_3[[1]])
names(auc) <- c("Una Variable", "Todas las variables", "Variables aleatorias")
auc
```

2. Para el ejemplo de regresi??n log??stica multinomial que
vimos en clase (clasificaci??n de d??gitos 0-9), construye la
gr??fica de coeficientes (secci??n 4.3.3) para:

- El modelo que vimos en clase donde no hab??an convergido los
coeficientes
- El modelo despu??s de correr hasta convergencia (usa la
 funci??n *multinom*)
 
 Compara las gr??ficas. ??Cu??l es m??s interpretable? ??Puedes ver
 el sobreajuste del segundo modelo en estas gr??ficas?


```{r}
# Cargar los datps
setwd("/Users/deliadelaguila/Documents/GitHub/aprendizaje-maquina-mcd")
digitos_entrena <- read_csv('datos/zip-train.csv')
digitos_prueba <- read_csv('datos/zip-test.csv')
names(digitos_entrena)[1] <- 'digito'
names(digitos_entrena)[2:257] <- paste0('pixel_', 1:256)
names(digitos_prueba)[1] <- 'digito'
names(digitos_prueba)[2:257] <- paste0('pixel_', 1:256)

# Entrenamiento y Matriz de Confusion de Entrenamiento
library(nnet)
mod_mult_1 <- multinom(digito ~ ., data = digitos_entrena, MaxNWt=100000, maxit = 20)

# Matriz de Confusion de Prueba
confusion_prueba_1 <- table(predict(mod_mult_1, newdata = digitos_prueba), digitos_prueba$digito)
round(prop.table(confusion_prueba_1, 2),2)
```


```{r}
# Error de Clasificaci??n
sum(diag(confusion_prueba_1))/sum(confusion_prueba_1)

```

```{r}
coefs <- coef(mod_mult_1)
coefs_reng <- coefs[1, , drop =FALSE]
coefs <- rbind(coefs_reng, coefs)
coefs[1 , ] <- 0

beta_df <- coefs[,-1] %>% as.data.frame %>% 
  mutate(digito = 0:(nrow(coefs)-1)) %>%
  gather(pixel, valor, contains('pixel')) %>%
  separate(pixel, into = c('str','pixel_no'), sep='_') %>%
  mutate(x = (as.integer(pixel_no)-1) %% 16, y = -((as.integer(pixel_no)-1) %/% 16))

tab_coef <- beta_df %>% select(digito, x, y, valor)
tab_coef_1 <- tab_coef
names(tab_coef_1) <- c('digito_1','x','y','valor_1')
tab_cruzada <- full_join(tab_coef_1, tab_coef) %>% mutate(dif = valor_1 - valor)

tab_cruzada_1 <- tab_cruzada %>% group_by(digito, digito_1) %>% 
  mutate(dif_s = (dif - mean(dif))/sd(dif)) %>%
  mutate(dif_p = pmin(pmax(dif_s, -2), 2))

ggplot(tab_cruzada_1, aes(x=x, y=y)) + geom_tile(aes(fill = dif_p)) + 
  facet_grid(digito_1~digito) + scale_fill_distiller(palette = "Spectral")

```

```{r}
# Entrenamiento y Matriz de Confusion de Entrenamiento
mod_mult_2 <- multinom(digito ~ ., data = digitos_entrena, MaxNWt=100000, maxit = 2000000)

# Matriz de Confusion de Prueba
confusion_prueba_2 <- table(predict(mod_mult_2, newdata = digitos_prueba), digitos_prueba$digito)
round(prop.table(confusion_prueba_2, 2),2)
```

```{r}
# Error de Clasificaci??n
sum(diag(confusion_prueba_2))/sum(confusion_prueba_2)

```

```{r}
coefs <- coef(mod_mult_2)
coefs_reng <- coefs[1, , drop =FALSE]
coefs <- rbind(coefs_reng, coefs)
coefs[1 , ] <- 0

beta_df <- coefs[,-1] %>% as.data.frame %>% 
  mutate(digito = 0:(nrow(coefs)-1)) %>%
  gather(pixel, valor, contains('pixel')) %>%
  separate(pixel, into = c('str','pixel_no'), sep='_') %>%
  mutate(x = (as.integer(pixel_no)-1) %% 16, y = -((as.integer(pixel_no)-1) %/% 16))

tab_coef <- beta_df %>% select(digito, x, y, valor)
tab_coef_2 <- tab_coef
names(tab_coef_2) <- c('digito_1','x','y','valor_1')
tab_cruzada <- full_join(tab_coef_2, tab_coef) %>% mutate(dif = valor_1 - valor)

tab_cruzada_2 <- tab_cruzada %>% group_by(digito, digito_1) %>% 
  mutate(dif_s = (dif - mean(dif))/sd(dif)) %>%
  mutate(dif_p = pmin(pmax(dif_s, -2), 2))

ggplot(tab_cruzada_2, aes(x=x, y=y)) + geom_tile(aes(fill = dif_p)) + 
  facet_grid(digito_1~digito) + scale_fill_distiller(palette = "Spectral")

```



